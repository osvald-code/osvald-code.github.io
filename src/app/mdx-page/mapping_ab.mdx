With chatgpt and other AIs becoming normative, a reoccurring issue presented itself to me: 
"How do I know if I have enough pre-requisite knowledge to verify that the generated result is correct?" 

First, I wish to eliminate the obvious issue. If you don't understand the output, you cannot verify it. If the output is in Korean, my pre-requisite knowledge of English is not enough. 

Great, now lets move beyond that. This thought originally occurred when I was searching for some code syntax. I needed to know if the Folders object I was working with was using .Count , . Length, etc. The browser offered a copilot generated solution to my issue: use a for loop to iterate all files and count them....
...yikes...
Now obviously I had enough pre-requisite knowledge to know that this is a poor answer. The data structure stores a variable counting the total number elements! But this got me thinking... if I were to ask it a question about law, business, physiology, etc.,  how would I know if the information I'm being presented is accurate? Moreover, how could I determine if I have the pre-requisite knowledge to properly determine the accuracy of the results? 

This led me to come across the Gell-Mann amnesia effect (add wiki link). This describes a common bias, in which a person is reading a newspaper. When reading about a field they have an expertise in, they find the flaws, and deem the source non-credible. Then they turn the page, and read a subject that they don't have much knowledge in, and they believe what is written. 
Sound familiar? Its how most of us treat AI at the moment. 

But here's where things get tricky - we can all recognize that: 
	a) any level of experience/knowledge could have incorrect information 
	b) while AI is wrong sometimes, it is often found helpful enough that the risk of a minor mistake is considered 'worth it'

So lets remove AI from this. 

Now the question becomes -> Do I have enough pre-requisite knowledge to know if the information being presented to me is correct?

Its an interesting question, and in a way, is unanswerable. there is no cap on knowledge, and its probably fair to say that the variability of information makes knowledge also somewhat temperament. 

So does this mean that it's impossible to ever know anything? well.. sort of, but for the sake of this discussion, lets operate under the limits of "truth is what we know until proven otherwise" 

So lets look at where we're at:
- We want to be able to tell if we have enough pre-requisite knowledge to understand something.
- Its impossible to hold all knowledge, and what knowledge we do hold is malleable
- We can use whatever knowledge we do have to produce results

I suppose this is the intent of accreditation - to ensure that someone becomes an expert by a verification process agreed on by an existing body. Well that's certainly a solid way to approach this problem, if falls short in:
- Poor accreditation implementation (via cheating, disorganization, politics, etc)
- Knowledge that is more obscure or new is possibly not associated with an accreditation body
- The average person doesn't have the necessary resources to pursue all areas they need to learn about

***to be continued***...




